# docker-compose.yml - 实训平台核心服务部署配置

services:
  # ==================== 基础设施服务 ====================

  # Nginx 反向代理
  nginx:
    image: nginx:alpine
    ports:
      - "8080:80"
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf:ro
    depends_on:
      - frontend
      - experiment-manager
      - jupyterhub
    networks:
      - training-network
    restart: always

  # PostgreSQL 数据库
  postgres:
    image: postgres:15
    environment:
      POSTGRES_USER: jupyterhub
      POSTGRES_PASSWORD: ${DB_PASSWORD:-changeme}
      POSTGRES_DB: jupyterhub
    volumes:
      - postgres-data:/var/lib/postgresql/data
    networks:
      - training-network
    restart: unless-stopped
    healthcheck:
      test: [ "CMD-SHELL", "pg_isready -U jupyterhub" ]
      interval: 10s
      timeout: 5s
      retries: 5

  # Redis 缓存
  redis:
    image: redis:7-alpine
    volumes:
      - redis-data:/data
    networks:
      - training-network
    restart: unless-stopped
    healthcheck:
      test: [ "CMD", "redis-cli", "ping" ]
      interval: 10s
      timeout: 3s
      retries: 3

  # ==================== 核心应用服务 ====================

  # 前端应用
  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    networks:
      - training-network
    restart: unless-stopped

  # 实验管理后端
  experiment-manager:
    build:
      context: ./backend
      dockerfile: Dockerfile
    ports:
      - "8001:8000"
    networks:
      - training-network
    environment:
      DATABASE_URL: postgresql://jupyterhub:${DB_PASSWORD:-changeme}@postgres/jupyterhub
      POSTGRES_SCHEMA: ${POSTGRES_SCHEMA:-experiment_manager}
      REDIS_URL: redis://redis:6379/0
      TAVILY_API_KEY: ${TAVILY_API_KEY:-}
      # JupyterHub multi-tenant integration
      JUPYTERHUB_INTERNAL_URL: http://jupyterhub:8000${JUPYTERHUB_BASE_URL:-/jupyter}
      JUPYTERHUB_PUBLIC_URL: ${JUPYTERHUB_PUBLIC_URL:-/jupyter}
      JUPYTERHUB_API_TOKEN: ${EXPERIMENT_MANAGER_API_TOKEN:-training-jhub-service-token}
      JUPYTER_WORKSPACE_UI: ${JUPYTER_WORKSPACE_UI:-lab}
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    restart: unless-stopped

  # JupyterHub
  jupyterhub:
    build:
      context: ./jupyterhub
      dockerfile: Dockerfile
    ports:
      - "8003:8000"
    volumes:
      # 挂载 Docker socket 以便启动用户容器
      - /var/run/docker.sock:/var/run/docker.sock
      # JupyterHub 数据持久化
      - jupyterhub-data:/srv/jupyterhub
      # 挂载配置文件（开发模式推荐）
      - ./jupyterhub/jupyterhub_config.py:/srv/jupyterhub/jupyterhub_config.py
    environment:
      # 数据库配置
      POSTGRES_DB: jupyterhub
      POSTGRES_HOST: postgres
      HUB_DB_URL: postgresql://jupyterhub:${DB_PASSWORD:-changeme}@postgres:5432/jupyterhub
      # Docker Spawner 配置
      # JupyterLab 镜像名称
      DOCKER_NOTEBOOK_IMAGE: training-lab:latest
      # Backend service token (for Hub API calls)
      EXPERIMENT_MANAGER_API_TOKEN: ${EXPERIMENT_MANAGER_API_TOKEN:-training-jhub-service-token}
      JUPYTERHUB_BASE_URL: ${JUPYTERHUB_BASE_URL:-/jupyter}
      ADMIN_ACCOUNTS: ${ADMIN_ACCOUNTS:-admin}
      TEACHER_ACCOUNTS: ${TEACHER_ACCOUNTS:-teacher_001,teacher_002,teacher_003,teacher_004,teacher_005}
    networks:
      - training-network
    depends_on:
      postgres:
        condition: service_healthy
      lab-image-builder:
        condition: service_completed_successfully
      data-loader:
        condition: service_completed_successfully
    restart: unless-stopped

  # 这是一个临时构建服务，用于构建学生镜像
  # 在 docker compose up 时会运行并退出
  lab-image-builder:
    build:
      context: .
      dockerfile: Dockerfile.student
    image: training-lab:latest
    command: echo "Student image built successfully"
    networks:
      - training-network

  # 数据加载服务：将宿主机实验文件同步到 Docker 卷
  data-loader:
    image: alpine:latest
    volumes:
      - ./experiments:/src
      - course-materials:/dst
    command: sh -c "cp -r /src/* /dst/ && echo 'Data sync complete'"
    networks:
      - training-network

  # ==================== AI 与智能服务 ====================

  # Ollama 本地大模型
  # ollama:
  #   image: ollama/ollama:latest
  #   volumes:
  #     - ollama-data:/root/.ollama
  #   ports:
  #     - "11434:11434"
  #   networks:
  #     - training-network
  #   restart: unless-stopped

  # AI 助手服务
  ai-assistant:
    build:
      context: ./ai-service
      dockerfile: Dockerfile
    ports:
      - "8002:8000"
    networks:
      - training-network
    environment:
      DEEPSEEK_API_KEY: ${DEEPSEEK_API_KEY:-}
      DEEPSEEK_BASE_URL: ${DEEPSEEK_BASE_URL:-https://api.deepseek.com}
      DEEPSEEK_MODEL: ${DEEPSEEK_MODEL:-deepseek-chat}
      TAVILY_API_KEY: ${TAVILY_API_KEY:-}
      CACHE_TTL: ${CACHE_TTL:-3600}
      MAX_HISTORY: ${MAX_HISTORY:-10}
    # depends_on:
    #   - ollama
    restart: unless-stopped

  # ==================== 监控服务 ====================

  prometheus:
    image: prom/prometheus:latest
    volumes:
      - ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - prometheus-data:/prometheus
    ports:
      - "9090:9090"
    networks:
      - training-network
    restart: unless-stopped
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'

  grafana:
    image: grafana/grafana:latest
    volumes:
      - grafana-data:/var/lib/grafana
      - ./monitoring/grafana-dashboards:/var/lib/grafana/dashboards
    ports:
      - "3001:3000"
    networks:
      - training-network
    environment:
      GF_SECURITY_ADMIN_PASSWORD: ${GRAFANA_PASSWORD:-admin}
      GF_INSTALL_PLUGINS: ${GF_INSTALL_PLUGINS:-}
    depends_on:
      - prometheus
    restart: unless-stopped

# ==================== 网络配置 ====================

networks:
  training-network:
    driver: bridge

# ==================== 数据卷配置 ====================

volumes:
  postgres-data:
  redis-data:
  jhub-home:
  jupyterhub-data:
  ollama-data:
  prometheus-data:
  grafana-data:
  course-materials:
  shared-datasets:
  shared-workspace:
